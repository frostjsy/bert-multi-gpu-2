{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import metrics\n",
    "import modeling\n",
    "import optimization\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_builder(dataset_path, seq_length, batch_size, is_training, max_eval_examples=None):\n",
    "    output_buffer_size = batch_size * 1000\n",
    "    \n",
    "    def extract_fn(data_record):\n",
    "        features = {\n",
    "            \"query_ids\": tf.FixedLenSequenceFeature(\n",
    "              [], tf.int64, allow_missing=True),\n",
    "            \"doc_ids\": tf.FixedLenSequenceFeature(\n",
    "              [], tf.int64, allow_missing=True),\n",
    "            \"label\": tf.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "\n",
    "        sample = tf.parse_single_example(data_record, features)\n",
    "        \n",
    "        query_ids = tf.cast(sample[\"query_ids\"], tf.int64)\n",
    "        doc_ids = tf.cast(sample[\"doc_ids\"], tf.int64)\n",
    "        label_ids = tf.cast(sample[\"label\"], tf.int64)\n",
    "        input_ids = tf.concat((query_ids, doc_ids), 0)\n",
    "        \n",
    "        query_segment_id = tf.zeros_like(query_ids)\n",
    "        doc_segment_id = tf.ones_like(doc_ids)\n",
    "        segment_ids = tf.concat((query_segment_id, doc_segment_id), 0)\n",
    "\n",
    "        input_mask = tf.ones_like(input_ids)\n",
    "\n",
    "        features = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"segment_ids\": segment_ids,\n",
    "            \"input_mask\": input_mask,\n",
    "            \"label_ids\": label_ids\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset([dataset_path])\n",
    "    dataset = dataset.map(extract_fn, num_parallel_calls=4).prefetch(output_buffer_size)\n",
    "\n",
    "    if is_training:\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(buffer_size=1000000)\n",
    "    else:\n",
    "        if max_eval_examples:\n",
    "            # Use at most this number of examples (debugging only).\n",
    "            dataset = dataset.take(max_eval_examples)\n",
    "            # pass\n",
    "            \n",
    "    dataset = dataset.apply(\n",
    "        tf.contrib.data.padded_batch_and_drop_remainder(\n",
    "            batch_size=batch_size,\n",
    "            padded_shapes={\n",
    "                \"input_ids\": [seq_length],\n",
    "                \"segment_ids\": [seq_length],\n",
    "                \"input_mask\": [seq_length],\n",
    "                \"label_ids\": []\n",
    "            },\n",
    "            padding_values={\n",
    "                \"input_ids\": tf.cast(0, dtype=tf.int64),\n",
    "                \"segment_ids\": tf.cast(0, dtype=tf.int64),\n",
    "                \"input_mask\":tf.cast(0, dtype=tf.int64),\n",
    "                \"label_ids\": tf.cast(0, dtype=tf.int64)\n",
    "            }))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBaseModel():\n",
    "    def __init__(self, batch_size, learning_rate, num_train_steps, num_warmup_steps, num_labels,\n",
    "                 seq_length, query_length, bert_config, use_one_hot_embeddings, is_training, is_fine_tuning, gpu_num):\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_train_steps = num_train_steps\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_labels = num_labels\n",
    "        self.seq_length = seq_length\n",
    "        self.query_length = query_length\n",
    "        self.bert_config = bert_config\n",
    "        self.use_one_hot_embeddings = use_one_hot_embeddings\n",
    "        self.is_training = is_training\n",
    "        self.is_fine_tuning = is_fine_tuning\n",
    "        self.gpu_num = gpu_num\n",
    "        self.gpu_step = int(self.batch_size / self.gpu_num)\n",
    "        self.initialize = True\n",
    "        \n",
    "        self.input_layer()\n",
    "        self.loss()\n",
    "        \n",
    "        devices = self.get_available_gpus()\n",
    "        print(\"Available Device:\", devices)\n",
    "        \n",
    "    def input_layer(self):\n",
    "        self.input_ids = tf.placeholder(tf.int32, [None, self.seq_length])\n",
    "        self.input_mask = tf.placeholder(tf.int32, [None, self.seq_length])\n",
    "        self.segment_ids = tf.placeholder(tf.int32, [None, self.seq_length])\n",
    "        self.label_ids = tf.placeholder(tf.int32, [None])\n",
    "        \n",
    "    # Source:\n",
    "    # https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n",
    "    def get_available_gpus(self):\n",
    "        \"\"\"\n",
    "            Returns a list of the identifiers of all visible GPUs.\n",
    "        \"\"\"\n",
    "        from tensorflow.python.client import device_lib\n",
    "        local_device_protos = device_lib.list_local_devices()\n",
    "        return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "    # see https://github.com/tensorflow/tensorflow/issues/9517\n",
    "    def assign_to_device(self, device, ps_device):\n",
    "        \"\"\"Returns a function to place variables on the ps_device.\n",
    "\n",
    "        Args:\n",
    "            device: Device for everything but variables\n",
    "            ps_device: Device to put the variables on. Example values are /GPU:0 and /CPU:0.\n",
    "\n",
    "        If ps_device is not set then the variables will be placed on the default device.\n",
    "        The best device for shared varibles depends on the platform as well as the\n",
    "        model. Start with CPU:0 and then test GPU:0 to see if there is an\n",
    "        improvement.\n",
    "        \"\"\"\n",
    "        PS_OPS = [\n",
    "            'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\n",
    "            'MutableHashTableOfTensors', 'MutableDenseHashTable'\n",
    "        ]\n",
    "        def _assign(op):\n",
    "            node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n",
    "            if node_def.op in PS_OPS:\n",
    "                return ps_device\n",
    "            else:\n",
    "                return device\n",
    "        return _assign\n",
    "    \n",
    "    def build(self, gpu_idx):\n",
    "        model = modeling.BertModel(\n",
    "            config=self.bert_config,\n",
    "            is_training=self.is_fine_tuning,\n",
    "            input_ids=self.input_ids[gpu_idx*self.gpu_step:(gpu_idx+1)*self.gpu_step],\n",
    "            input_mask=self.input_mask[gpu_idx*self.gpu_step:(gpu_idx+1)*self.gpu_step],\n",
    "            token_type_ids=self.segment_ids[gpu_idx*self.gpu_step:(gpu_idx+1)*self.gpu_step],\n",
    "            use_one_hot_embeddings=self.use_one_hot_embeddings)\n",
    "        \n",
    "        print(\"GPU:\", gpu_idx)\n",
    "        \n",
    "        # [batch_size, hidden_size]\n",
    "        output_layer = model.get_pooled_output()\n",
    "        hidden_size = output_layer.shape[-1].value\n",
    "        # applied dropout if training\n",
    "        output_layer = tf.layers.dropout(inputs=output_layer, rate=0.1, training=self.is_training)\n",
    "        logits = tf.layers.dense(inputs=output_layer, units=self.num_labels, name='dense', reuse=tf.AUTO_REUSE)\n",
    "        self.log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "        one_hot_labels = tf.one_hot(self.label_ids[gpu_idx*self.gpu_step:(gpu_idx+1)*self.gpu_step], depth=self.num_labels, dtype=tf.float32)\n",
    "        \n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * self.log_probs, axis=-1)\n",
    "        self.total_loss = tf.reduce_mean(per_example_loss)\n",
    "      \n",
    "    def loss(self):\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.update_op, self.update_loss = self.create_parallel_optimization(optimizer)\n",
    "        \n",
    "    def create_parallel_optimization(self, optimizer, controller=\"/cpu:0\"):\n",
    "        # This function is defined below; it returns a list of device ids like\n",
    "        # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3\"\n",
    "        # 0 represent 2\n",
    "        # 1 represent 3\n",
    "        # `['/gpu:0', '/gpu:1']`\n",
    "        devices = self.get_available_gpus()\n",
    "\n",
    "        # This list keeps track of the gradients per tower and the losses\n",
    "        tower_grads = []\n",
    "        losses = []\n",
    "        \n",
    "        # Get the current variable scope so we can reuse all variables we need once we get\n",
    "        # to the second iteration of the loop below\n",
    "        with tf.variable_scope(tf.get_variable_scope()) as outer_scope:\n",
    "            for i, id in enumerate(devices):\n",
    "                # custom number of GPU\n",
    "                if i >= self.gpu_num:\n",
    "                    break\n",
    "                name = 'tower_{}'.format(i)\n",
    "                # Use the assign_to_device function to ensure that variables are created on the\n",
    "                # controller.\n",
    "                with tf.device(self.assign_to_device(id, controller)), tf.name_scope(name):\n",
    "                    # Compute loss and gradients, but don't apply them yet\n",
    "                    if self.initialize:\n",
    "                        self.build(i)\n",
    "                    loss = self.total_loss\n",
    "            \n",
    "                    with tf.name_scope(\"compute_gradients\"):\n",
    "                        # `compute_gradients` returns a list of (gradient, variable) pairs\n",
    "                        tvars = tf.trainable_variables()\n",
    "                        tvars = list(filter(lambda x: \"bert/pooler\" not in x.name, tvars))\n",
    "                        grads = optimizer.compute_gradients(loss, var_list=tvars)\n",
    "                        tower_grads.append(grads)\n",
    "                    losses.append(loss)\n",
    "\n",
    "                # After the first iteration, we want to reuse the variables.\n",
    "                outer_scope.reuse_variables()\n",
    "                \n",
    "        self.initialize = False\n",
    "        # Apply the gradients on the controlling device\n",
    "        with tf.name_scope(\"apply_gradients\"), tf.device(controller):\n",
    "            # Note that what we are doing here mathematically is equivalent to returning the\n",
    "            # average loss over the towers and compute the gradients relative to that.\n",
    "            # Unfortunately, this would place all gradient-computations on one device, which is\n",
    "            # why we had to compute the gradients above per tower and need to average them here.\n",
    "\n",
    "            # This function is defined below; it takes the list of (gradient, variable) lists\n",
    "            # and turns it into a single (gradient, variables) list.\n",
    "            gradients = self.average_gradients(tower_grads)\n",
    "            global_step = tf.train.get_or_create_global_step()\n",
    "            gradients, norm_summary_ops = self.clip_grads(gradients, 1.0, True, global_step)\n",
    "            apply_gradient_op = optimizer.apply_gradients(gradients, global_step)\n",
    "            avg_loss = tf.reduce_mean(losses)\n",
    "            \n",
    "        return apply_gradient_op, avg_loss\n",
    "    \n",
    "    def average_gradients(self, tower_grads):\n",
    "        \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "        Note that this function provides a synchronization point across all towers.\n",
    "        Args:\n",
    "        tower_grads: List of lists of (gradient, variable) tuples. The outer list ranges\n",
    "            over the devices. The inner list ranges over the different variables.\n",
    "        Returns:\n",
    "                List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "                across all towers.\n",
    "        \"\"\"\n",
    "        # calculate average gradient for each shared variable across all GPUs\n",
    "        average_grads = []\n",
    "        \n",
    "        for grad_and_vars in zip(*tower_grads):\n",
    "            # Note that each grad_and_vars looks like the following:\n",
    "            #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "            # We need to average the gradients across each GPU.\n",
    "            \n",
    "            g0, v0 = grad_and_vars[0]\n",
    "            if isinstance(g0, tf.IndexedSlices):\n",
    "                # If the gradient is type IndexedSlices then this is a sparse\n",
    "                # gradient with attributes indices and values.\n",
    "                # To average, need to concat them individually then create\n",
    "                # a new IndexedSlices object.\n",
    "                indices = []\n",
    "                values = []\n",
    "                for g, v in grad_and_vars:\n",
    "                    indices.append(g.indices)\n",
    "                    values.append(g.values)\n",
    "                all_indices = tf.concat(indices, 0)\n",
    "                avg_values = tf.concat(values, 0) / len(grad_and_vars)\n",
    "                # deduplicate across indices\n",
    "                av, ai = self._deduplicate_indexed_slices(avg_values, all_indices)\n",
    "                grad = tf.IndexedSlices(av, ai, dense_shape=g0.dense_shape)\n",
    "\n",
    "            else:\n",
    "                # a normal tensor can just do a simple average\n",
    "                # Keep in mind that the Variables are redundant because they are shared\n",
    "                # across towers. So .. we will just return the first tower's pointer to\n",
    "                # the Variable.\n",
    "                grads = [g for g, _ in grad_and_vars]\n",
    "                grad = tf.reduce_mean(grads, 0)\n",
    "\n",
    "            # the Variables are redundant because they are shared\n",
    "            # across towers. So.. just return the first tower's pointer to\n",
    "            # the Variable.\n",
    "            v = grad_and_vars[0][1]\n",
    "            grad_and_var = (grad, v)\n",
    "            average_grads.append(grad_and_var)\n",
    "        return average_grads\n",
    "    \n",
    "    def _deduplicate_indexed_slices(self, values, indices):\n",
    "        \"\"\"Sums `values` associated with any non-unique `indices`.\n",
    "        Args:\n",
    "          values: A `Tensor` with rank >= 1.\n",
    "          indices: A one-dimensional integer `Tensor`, indexing into the first\n",
    "          dimension of `values` (as in an IndexedSlices object).\n",
    "        Returns:\n",
    "          A tuple of (`summed_values`, `unique_indices`) where `unique_indices` is a\n",
    "          de-duplicated version of `indices` and `summed_values` contains the sum of\n",
    "          `values` slices associated with each unique index.\n",
    "        \"\"\"\n",
    "        unique_indices, new_index_positions = tf.unique(indices)\n",
    "        summed_values = tf.unsorted_segment_sum(values, new_index_positions, tf.shape(unique_indices)[0])\n",
    "        return (summed_values, unique_indices)\n",
    "    \n",
    "    def clip_by_global_norm_summary(self, t_list, clip_norm, norm_name, variables):\n",
    "        # wrapper around tf.clip_by_global_norm that also does summary ops of norms\n",
    "\n",
    "        # compute norms\n",
    "        # use global_norm with one element to handle IndexedSlices vs dense\n",
    "        norms = [tf.global_norm([t]) for t in t_list]\n",
    "\n",
    "        # summary ops before clipping\n",
    "        summary_ops = []\n",
    "        for ns, v in zip(norms, variables):\n",
    "            name = 'norm_pre_clip/' + v.name.replace(\":\", \"_\")\n",
    "            summary_ops.append(tf.summary.scalar(name, ns))\n",
    "\n",
    "        # clip\n",
    "        clipped_t_list, tf_norm = tf.clip_by_global_norm(t_list, clip_norm)\n",
    "\n",
    "        # summary ops after clipping\n",
    "        norms_post = [tf.global_norm([t]) for t in clipped_t_list]\n",
    "        for ns, v in zip(norms_post, variables):\n",
    "            name = 'norm_post_clip/' + v.name.replace(\":\", \"_\")\n",
    "            summary_ops.append(tf.summary.scalar(name, ns))\n",
    "\n",
    "        summary_ops.append(tf.summary.scalar(norm_name, tf_norm))\n",
    "\n",
    "        return clipped_t_list, tf_norm, summary_ops\n",
    "\n",
    "\n",
    "    def clip_grads(self, grads, all_clip_norm_val, do_summaries, global_step):\n",
    "        # grads = [(grad1, var1), (grad2, var2), ...]\n",
    "        def _clip_norms(grad_and_vars, val, name):\n",
    "            # grad_and_vars is a list of (g, v) pairs\n",
    "            grad_tensors = [g for g, v in grad_and_vars]\n",
    "            vv = [v for g, v in grad_and_vars]\n",
    "            scaled_val = val\n",
    "            if do_summaries:\n",
    "                clipped_tensors, g_norm, so = self.clip_by_global_norm_summary(\n",
    "                    grad_tensors, scaled_val, name, vv)\n",
    "            else:\n",
    "                so = []\n",
    "                clipped_tensors, g_norm = tf.clip_by_global_norm(\n",
    "                    grad_tensors, scaled_val)\n",
    "\n",
    "            ret = []\n",
    "            for t, (g, v) in zip(clipped_tensors, grad_and_vars):\n",
    "                ret.append((t, v))\n",
    "\n",
    "            return ret, so\n",
    "\n",
    "        ret, summary_ops = _clip_norms(grads, all_clip_norm_val, 'norm_grad')\n",
    "        assert len(ret) == len(grads)\n",
    "        return ret, summary_ops\n",
    "    \n",
    "    def train(self, dataset, ckpt_dir, output_dir, save_checkpoints_step):\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        \n",
    "        # we can load \"bert\" variable only, the rest should be trained by our self\n",
    "        tvars = tf.trainable_variables()\n",
    "        tvars = list(filter(lambda x: \"bert\" in x.name, tvars))\n",
    "        saver = tf.train.Saver(var_list=tvars)\n",
    "        saver2 = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.restore(sess, ckpt_dir)\n",
    "#             saver2.restore(sess, ckpt_dir)\n",
    "            \n",
    "            train_iterator = dataset.make_one_shot_iterator()\n",
    "            next_element = train_iterator.get_next()\n",
    "\n",
    "            loss = []\n",
    "            min_loss = 1\n",
    "            step = 0\n",
    "            print(\"Start training!\")\n",
    "            \n",
    "            for i in range(self.num_train_steps):\n",
    "                features = sess.run(next_element)\n",
    "                train_loss_steps, _ = sess.run(\n",
    "                    [self.update_loss, self.update_op], \n",
    "                    feed_dict={\n",
    "                        self.input_ids: features[\"input_ids\"],\n",
    "                        self.input_mask: features[\"input_mask\"],\n",
    "                        self.segment_ids: features[\"segment_ids\"],\n",
    "                        self.label_ids: features[\"label_ids\"]\n",
    "                    })\n",
    "                loss.append(train_loss_steps)\n",
    "                step += 1\n",
    "\n",
    "                if i % save_checkpoints_step==0:\n",
    "                    loss = np.sum(loss)\n",
    "                    loss /= step;\n",
    "\n",
    "                    time_tuple = time.localtime()\n",
    "                    time_string = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time_tuple)\n",
    "                    print(time_string + \" {:d} step loss: {:.4f}\".format(i, loss))\n",
    "\n",
    "                    with open(output_dir + \"loss.txt\", \"a\") as text_file:\n",
    "                        text_file.write(time_string + \" {:d} step loss: {:.4f}\\n\".format(i, loss))\n",
    "\n",
    "                    saver2.save(sess, output_dir + 'bert-model.ckpt')\n",
    "                    loss = []\n",
    "                    step = 0\n",
    "                    print(\"save checkpoint in {}\".format(output_dir + 'bert-model.ckpt-' + str(i)))\n",
    "        \n",
    "    def predict(self, dataset, ckpt_dir, output_dir, batch_size, max_eval_examples):\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.restore(sess, ckpt_dir)\n",
    "            \n",
    "            train_iterator = dataset.make_one_shot_iterator()\n",
    "            next_element = train_iterator.get_next()\n",
    "            \n",
    "            step = max_eval_examples / batch_size\n",
    "            log_probs = np.zeros((1, num_labels))\n",
    "            labels = np.zeros((1, 1))\n",
    "            \n",
    "            print(\"Start predicting!\")\n",
    "            \n",
    "            for i in range(int(step)):\n",
    "                features = sess.run(next_element)\n",
    "                log_prob = sess.run(\n",
    "                    self.log_probs, \n",
    "                    feed_dict={\n",
    "                        self.input_ids: features[\"input_ids\"],\n",
    "                        self.input_mask: features[\"input_mask\"],\n",
    "                        self.segment_ids: features[\"segment_ids\"]\n",
    "                    })\n",
    "                \n",
    "                log_probs = np.concatenate((log_probs, log_prob), axis=0)\n",
    "                labels = np.concatenate((labels, features[\"label_ids\"].reshape(-1, 1)), axis=0)\n",
    "                \n",
    "                if i % 100 == 0:\n",
    "                    time_tuple = time.localtime()\n",
    "                    time_string = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time_tuple)\n",
    "                    print(time_string + \" {:d} step\".format(i))\n",
    "                    \n",
    "                    with open(output_dir + \"/eval_step.txt\", \"a\") as text_file:\n",
    "                        text_file.write(time_string + \" {:d} step\\n\".format(i))\n",
    "                        \n",
    "            print(\"End predicting!\")\n",
    "            \n",
    "            log_probs = np.delete(log_probs, 0, 0)\n",
    "            labels = np.delete(labels, 0, 0)\n",
    "            \n",
    "        return log_probs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "data_dir = '../MSMARCO_tfrecord/'\n",
    "bert_config_file = '../uncased_L-12_H-768_A-12/bert_config.json'\n",
    "bert_config_file_large = '../uncased_L-24_H-1024_A-16/bert_config.json'\n",
    "\n",
    "init_checkpoint = '../uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "init_checkpoint_large = '../uncased_L-24_H-1024_A-16/bert_model.ckpt'\n",
    "\n",
    "output_dir = './model_dense_multi_GPU/'\n",
    "\n",
    "num_gpu = 1\n",
    "is_training = True\n",
    "is_fine_tuning = False\n",
    "\n",
    "num_labels = 2\n",
    "max_seq_length = 512\n",
    "query_length = 64\n",
    "document_length = 448 # 512 - 64 = 448\n",
    "train_batch_size = 8\n",
    "learning_rate = 1e-5\n",
    "num_train_steps = 400000\n",
    "num_warmup_steps = 0\n",
    "save_checkpoints_steps = 500\n",
    "iterations_per_loop = 1000\n",
    "\n",
    "num_warmup_steps = num_warmup_steps * iterations_per_loop\n",
    "num_train_steps = num_train_steps * iterations_per_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file_large)\n",
    "dataset = input_builder(dataset_path=data_dir + \"/dataset_train.tf\", seq_length=max_seq_length,\n",
    "                        batch_size=train_batch_size, is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0\n",
      "Available Device: ['/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "Bert = BertBaseModel(batch_size=train_batch_size, learning_rate=learning_rate, num_train_steps=num_train_steps, \n",
    "                     num_warmup_steps=num_warmup_steps, num_labels=num_labels, seq_length=max_seq_length, \n",
    "                     query_length=query_length, bert_config=bert_config, use_one_hot_embeddings=False, \n",
    "                     is_training=is_training, is_fine_tuning=is_fine_tuning, gpu_num=num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "Bert.train(dataset=dataset, ckpt_dir=init_checkpoint_large, output_dir=output_dir, save_checkpoints_step=save_checkpoints_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_checkpoint_cnn = './model_VGG16_nonlinear_zero_padding/cnn-model.ckpt'\n",
    "output_dir = './output_VGG16_nonlinear_zero_padding'\n",
    "\n",
    "msmarco_output = True\n",
    "max_eval_example = 350\n",
    "num_eval_docs = 1000\n",
    "eval_batch_size = 100\n",
    "\n",
    "dev_size = 6980\n",
    "eval_size = 6800\n",
    "\n",
    "METRICS_MAP = ['MAP', 'RPrec', 'MRR', 'NDCG', 'MRR@10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_sampling = np.arange(0, 3490)\n",
    "np.random.shuffle(uniform_sampling)\n",
    "uniform_sampling = uniform_sampling[:max_eval_example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = uniform_sampling.argsort()\n",
    "dataset_uniform_sampling_ordered = []\n",
    "\n",
    "for i in range(len(uniform_sampling)):\n",
    "    dataset_uniform_sampling_ordered.append(uniform_sampling[idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# development only\n",
    "Bert = BertBaseModel(batch_size=eval_batch_size, learning_rate=learning_rate, num_train_steps=num_train_steps, \n",
    "                     num_warmup_steps=num_warmup_steps, num_labels=num_labels, seq_length=max_seq_length, \n",
    "                     query_length=query_length, bert_config=bert_config, use_one_hot_embeddings=False, is_training=False)\n",
    "\n",
    "\n",
    "if (max_eval_example):\n",
    "    max_eval_examples = max_eval_example * num_eval_docs\n",
    "\n",
    "dataset_eval = input_builder(dataset_path=data_dir + \"/dataset_dev.tf\", \n",
    "                              seq_length=max_seq_length, batch_size=eval_batch_size, is_training=False)\n",
    "\n",
    "msmarco_file = tf.gfile.Open(output_dir + \"/msmarco_predictions_dev.tsv\", \"w\")\n",
    "query_docids_map = []\n",
    "with tf.gfile.Open(data_dir + \"/query_doc_ids_dev.txt\") as ref_file:\n",
    "    for line in ref_file:\n",
    "        query_docids_map.append(line.strip().split(\"\\t\"))\n",
    "\n",
    "# log_prob, label = Bert.predict(dataset=dataset_eval, ckpt_dir=init_checkpoint_cnn, output_dir=output_dir, \n",
    "#                       batch_size=eval_batch_size, max_eval_examples=max_eval_examples)\n",
    "\n",
    "# dataset: whole dataset(do not use max_eval_examples parameter of input_builder)\n",
    "# dataset_reservoir: index of reservoir sampling\n",
    "# size: size of whole dataset(dataset_dev or dataset_eval)\n",
    "log_prob, label = Bert.predict_uniform_sampling(dataset=dataset_eval, dataset_reservoir=dataset_uniform_sampling_ordered, \n",
    "                                         size=dev_size, ckpt_dir=init_checkpoint_cnn, output_dir=output_dir, \n",
    "                                         batch_size=eval_batch_size, max_eval_examples=max_eval_examples)\n",
    "\n",
    "\n",
    "all_metrics = np.zeros(len(METRICS_MAP))\n",
    "example_idx = 0\n",
    "print(\"Start evaluation!\")\n",
    "time_tuple = time.localtime()\n",
    "time_string = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time_tuple)\n",
    "print(time_string)\n",
    "\n",
    "for i in range(0, max_eval_examples, num_eval_docs):\n",
    "    log_probs = log_prob[i:i+num_eval_docs]\n",
    "    labels = label[i:i+num_eval_docs]\n",
    "    \n",
    "    scores = log_probs[:, 1]\n",
    "    pred_docs = scores.argsort()[::-1]\n",
    "    gt = set(list(np.where(labels > 0)[0]))\n",
    "    all_metrics += metrics.metrics(\n",
    "          gt=gt, pred=pred_docs, metrics_map=METRICS_MAP)\n",
    "\n",
    "    start_idx = example_idx * num_eval_docs\n",
    "    end_idx = (example_idx + 1) * num_eval_docs\n",
    "    query_ids, doc_ids = zip(*query_docids_map[start_idx:end_idx])\n",
    "    assert len(set(query_ids)) == 1, \"Query ids must be all the same.\"\n",
    "    query_id = query_ids[0]\n",
    "    rank = 1\n",
    "    for doc_idx in pred_docs:\n",
    "        doc_id = doc_ids[doc_idx]\n",
    "        # Skip fake docs, as they are only used to ensure that each query\n",
    "        # has 1000 docs.\n",
    "        if doc_id != \"00000000\":\n",
    "            msmarco_file.write(\"\\t\".join((query_id, doc_id, str(rank))) + \"\\n\")\n",
    "            rank += 1\n",
    "\n",
    "    example_idx += 1\n",
    "    \n",
    "msmarco_file.close()\n",
    "all_metrics /= example_idx\n",
    "print(\"Eval dev:\")\n",
    "print(\"  \".join(METRICS_MAP))\n",
    "print(all_metrics)\n",
    "\n",
    "with open(output_dir + \"/score.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"Eval dev:\\n\")\n",
    "    text_file.write(\"MAP  RPrec  MRR  NDCG  MRR@10\\n\")\n",
    "    for each in all_metrics:\n",
    "        text_file.write(\"{:6f}\".format(each) + \" \")\n",
    "\n",
    "print(\"End evaluation!\")\n",
    "time_tuple = time.localtime()\n",
    "time_string = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time_tuple)\n",
    "print(time_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
